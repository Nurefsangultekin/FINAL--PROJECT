from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA

# FAISS veritabanÄ±nÄ± yÃ¼kle
vector_db = FAISS.load_local("legal_vector_index", OpenAIEmbeddings(), allow_dangerous_deserialization=True)

# LLM modelini oluÅŸtur (gpt-3.5 veya gpt-4 API key'ine gÃ¶re Ã§alÄ±ÅŸÄ±r)
llm = ChatOpenAI(model="gpt-3.5-turbo")

# Soru-Cevap zinciri oluÅŸtur (retriever, FAISS iÃ§inden belge Ã§eker)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vector_db.as_retriever(search_kwargs={"k": 4}),
    return_source_documents=True
)

# KullanÄ±cÄ±dan doÄŸal dilde soru al ve cevabÄ± Ã¼ret
if __name__ == "__main__":
    query = input("ğŸ“¨ Sorunuzu yazÄ±n: ")
    result = qa_chain(query)
    
    print("\nğŸ¤– Chatbot YanÄ±tÄ±:\n")
    print(result['result'])

    print("\nğŸ“„ KullanÄ±lan Belgeler:")
    for doc in result["source_documents"]:
        print("-" * 40)
        print(doc.page_content[:500])  # Ä°lk 500 karakteri yaz
